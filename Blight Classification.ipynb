{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px # quick plotting of data \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression  # basic classification model for initial exploration\n",
    "from sklearn.ensemble import RandomForestClassifier # classification model for higher performance and  generability\n",
    "from sklearn.model_selection import GridSearchCV # for parameter tuning \n",
    "from sklearn.model_selection import cross_val_score # cross validation of predictive models \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from datetime import datetime \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data Sets/Blight/train.csv\", encoding = 'latin1', low_memory = False)  #standard ucf-8 encoding cannot decode csv\n",
    "df_test = pd.read_csv(\"Data Sets/Blight/test.csv\")\n",
    "df_latlons = pd.read_csv(\"Data Sets/Blight/latlons.csv\")\n",
    "df_addresses = pd.read_csv(\"Data Sets/Blight/addresses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features avaliable for classification:\n",
    "\n",
    "<br>\n",
    "       'ticket_id', 'agency_name', 'inspector_name', 'violator_name',\n",
    "       'violation_street_number', 'violation_street_name',\n",
    "       'violation_zip_code', 'mailing_address_str_number',\n",
    "       'mailing_address_str_name', 'city', 'state', 'zip_code',\n",
    "       'non_us_str_code', 'country', 'ticket_issued_date', 'hearing_date',\n",
    "       'violation_code', 'violation_description', 'disposition', 'fine_amount',\n",
    "       'admin_fee', 'state_fee', 'late_fee', 'discount_amount',\n",
    "       'clean_up_cost', 'judgment_amount', 'payment_amount', 'balance_due',\n",
    "       'payment_date', 'payment_status', 'collection_status',\n",
    "       'grafitti_status', 'compliance_detail'\n",
    "<br>\n",
    "\n",
    "Of these features, features related to the address can be dropped after the table is joinned with the latlon table as information regarding the physical location of the address is presented in the latlon table as lat & lon values.\n",
    "\n",
    "Additionally, fields associated with the payment of the fines can also be dropped those are fields associated with the payment itself being made and won't be avaliable come testing.\n",
    "\n",
    "Lastly, the field associated with the violator him or herself should also be dropped to avoid labelling the possibility of complaince on who the violator is. \n",
    "\n",
    "Rows with no data on complaince dropped as NA on complaince means that violator is given incorrect verdict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id                          0\n",
       "agency_name                        0\n",
       "inspector_name                     0\n",
       "violator_name                     34\n",
       "violation_street_number            0\n",
       "violation_street_name              0\n",
       "violation_zip_code            250306\n",
       "mailing_address_str_number      3602\n",
       "mailing_address_str_name           4\n",
       "city                               0\n",
       "state                             93\n",
       "zip_code                           1\n",
       "non_us_str_code               250303\n",
       "country                            0\n",
       "ticket_issued_date                 0\n",
       "hearing_date                   12491\n",
       "violation_code                     0\n",
       "violation_description              0\n",
       "disposition                        0\n",
       "fine_amount                        1\n",
       "admin_fee                          0\n",
       "state_fee                          0\n",
       "late_fee                           0\n",
       "discount_amount                    0\n",
       "clean_up_cost                      0\n",
       "judgment_amount                    0\n",
       "payment_amount                     0\n",
       "balance_due                        0\n",
       "payment_date                  209193\n",
       "payment_status                     0\n",
       "collection_status             213409\n",
       "grafitti_status               250305\n",
       "compliance_detail                  0\n",
       "compliance                     90426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum() # check for columns with null vals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating 'agency_name' on Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compliance                                                    1.000000\n",
       "agency_name_Buildings, Safety Engineering & Env Department   -0.055637\n",
       "agency_name_Department of Public Works                        0.046939\n",
       "agency_name_Detroit Police Department                         0.038672\n",
       "agency_name_Health Department                                -0.005559\n",
       "agency_name_Neighborhood City Halls                          -0.000699\n",
       "Name: compliance, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agency_cols = ['agency_name', 'compliance']\n",
    "df_agency = df_train[agency_cols]\n",
    "df_agency = df_agency.dropna()\n",
    "dum = pd.get_dummies(df_agency)\n",
    "dum.corr().loc['compliance']  ## 'agency_name' has little to no effect on compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating 'inspector_name' on Compliance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector_cols = ['inspector_name', 'compliance']\n",
    "df_inspector = df_train[inspector_cols]\n",
    "df_inspector = df_inspector.dropna()\n",
    "dum = pd.get_dummies(df_inspector)\n",
    "(dum.corr().loc['compliance'] > 0.05).sum() ## 'inspector_name' has little to no effect on compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating 'violation_code' on Compliance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violation_cols = ['violation_code', 'compliance']\n",
    "df_violation = df_train[violation_cols]\n",
    "df_violation = df_violation.dropna()\n",
    "dum = pd.get_dummies(df_violation)\n",
    "(dum.corr().loc['compliance'] > 0.05).sum() ## 'violation_code' has little to no effect on compliance -- thus \n",
    "                                           ##  'violation description' should also have no effect on compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating 'grafitti_status' on Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRAFFITI TICKET    1\n",
       "Name: grafitti_status, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_train.grafitti_status)  ## number of samples with valid information for this feature too small "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating 'disposition' on Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compliance                                        1.000000\n",
       "disposition_Responsible (Fine Waived) by Deter    0.124956\n",
       "disposition_Responsible by Admission              0.238997\n",
       "disposition_Responsible by Default               -0.335455\n",
       "disposition_Responsible by Determination          0.202819\n",
       "Name: compliance, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disposition_cols = ['disposition', 'compliance']\n",
    "df_disposition = df_train[~df_train.compliance.isna()]\n",
    "df_disposition = df_disposition[disposition_cols]\n",
    "dum = pd.get_dummies(df_disposition)\n",
    "dum.corr().loc['compliance'] ## 'disposition' has an effect on compliance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating datetime Feature Fields "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of Specific Day of the Week on Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    ticket_issued_date  compliance\n",
       " ticket_issued_date            1.000000    0.006522\n",
       " compliance                    0.006522    1.000000,\n",
       "               hearing_date  compliance\n",
       " hearing_date      1.000000   -0.025301\n",
       " compliance       -0.025301    1.000000)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_dates = ['ticket_issued_date','hearing_date', 'compliance']\n",
    "df_temp = df_train.loc[:,cols_dates]\n",
    "df_temp.loc[:,cols_dates[0]] = pd.to_datetime(df_temp[cols_dates[0]])\n",
    "df_temp.loc[:,cols_dates[1]] = pd.to_datetime(df_temp[cols_dates[1]]) # Set up table for investigation\n",
    "\n",
    "df_temp.loc[:, cols_dates[0]] = df_temp[cols_dates[0]].dt.weekday\n",
    "df_temp.loc[:, cols_dates[1]] = df_temp[cols_dates[1]].dt.weekday\n",
    "(df_temp[['ticket_issued_date' , 'compliance']].corr(), df_temp[['hearing_date' , 'compliance']].corr())\n",
    "## Day of the week has little to no effect on compliance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of Specific Month of the Year on Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    ticket_issued_date  compliance\n",
       " ticket_issued_date            1.000000   -0.040555\n",
       " compliance                   -0.040555    1.000000,\n",
       "               hearing_date  compliance\n",
       " hearing_date      1.000000   -0.032841\n",
       " compliance       -0.032841    1.000000)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_dates = ['ticket_issued_date','hearing_date', 'compliance']\n",
    "df_temp = df_train.loc[:,cols_dates]\n",
    "df_temp.loc[:,cols_dates[0]] = pd.to_datetime(df_temp[cols_dates[0]])\n",
    "df_temp.loc[:,cols_dates[1]] = pd.to_datetime(df_temp[cols_dates[1]]) # Set up table for investigation\n",
    "\n",
    "df_temp.loc[:, cols_dates[0]] = df_temp[cols_dates[0]].dt.month\n",
    "df_temp.loc[:, cols_dates[1]] = df_temp[cols_dates[1]].dt.month\n",
    "(df_temp[['ticket_issued_date' , 'compliance']].corr(), df_temp[['hearing_date' , 'compliance']].corr())\n",
    "## Specific month has little to no effect on compliance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of the Difference Between Issued Date and Hearing Date on Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliance</th>\n",
       "      <th>issued_to_hearing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compliance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>issued_to_hearing</td>\n",
       "      <td>0.095732</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   compliance  issued_to_hearing\n",
       "compliance           1.000000           0.095732\n",
       "issued_to_hearing    0.095732           1.000000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_dates = ['ticket_issued_date','hearing_date', 'compliance']\n",
    "df_temp = df_train.loc[:,cols_dates]\n",
    "df_temp.loc[:,cols_dates[0]] = pd.to_datetime(df_temp[cols_dates[0]])\n",
    "df_temp.loc[:,cols_dates[1]] = pd.to_datetime(df_temp[cols_dates[1]]) # Set up table for investigation\n",
    "\n",
    "df_temp.loc[:,'ticket_issued_date'] = pd.DatetimeIndex(df_temp['ticket_issued_date']).astype(int) ## Covert time to UNIX\n",
    "df_temp.loc[:,'hearing_date'] = pd.DatetimeIndex(df_temp['hearing_date']).astype(int) \n",
    "df_temp.loc[:,'issued_to_hearing'] = df_temp[cols_dates[1]] - df_temp[cols_dates[0]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_temp.loc[:,'issued_to_hearing'] = scaler.fit_transform(df_temp[['issued_to_hearing']])\n",
    "\n",
    "df_temp[['compliance', 'issued_to_hearing']].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Testing - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93301226, 0.93363773, 0.93332499, 0.93401301, 0.93360645])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joining addresses to latlon to get latlon of each address\n",
    "df_addresses = df_addresses.merge(df_latlons, how = 'inner', left_on = 'address', right_on = 'address').dropna()\n",
    "\n",
    "\n",
    "## Joining addresses to df_train & df_test to that they will contain latlon \n",
    "df_train = df_train.merge(df_addresses, how = 'inner', left_on = 'ticket_id', right_on = 'ticket_id' )\n",
    "df_test = df_test.merge(df_addresses, how = 'inner', left_on = 'ticket_id', right_on = 'ticket_id')\n",
    "\n",
    "\n",
    "## Removing records where case is dropped \n",
    "df_train = df_train[~(df_train['compliance'].isna())]\n",
    "\n",
    "\n",
    "## Test cols with addresses and other qualitative fields removed along with fields with na\n",
    "cols_train = [ 'fine_amount', 'admin_fee', 'state_fee', 'late_fee', 'discount_amount',\n",
    "'clean_up_cost', 'disposition','judgment_amount', 'lat', 'lon']\n",
    "\n",
    "cols_all = cols_train + ['compliance']\n",
    "\n",
    "df_train_X = pd.get_dummies(df_train[cols_train])\n",
    "\n",
    "df_train_y = df_train['compliance']\n",
    "\n",
    "logreg = LogisticRegression(solver = 'lbfgs', max_iter = 300, penalty = 'l2')\n",
    "\n",
    "cross_val_score(logreg, df_train_X, df_train_y,\n",
    "                cv = ShuffleSplit(n_splits = 5, test_size = 0.2),\n",
    "               error_score = 'raise') ## custom cv to ensure real randomization of splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare perfomance to Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92744785, 0.92744558, 0.92747459, 0.92747459, 0.92747459])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clas = DummyClassifier(strategy = 'most_frequent')\n",
    "dummy_clas.fit(X_train, y_train)\n",
    "cross_val_score(dummy_clas, df_train_X, df_train_y, cv= 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model can consistently outperform the dummy classifier but only by a small amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Positive Class only Training Set - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10425531914893617"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train_X, df_train_y)\n",
    "custom_test = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "custom_test = custom_test[custom_test['compliance'] == 1]\n",
    "custom_test_X = custom_test.iloc[:,:-1]\n",
    "custom_test_y = custom_test['compliance']\n",
    "\n",
    "\n",
    "logreg_temp = LogisticRegression(solver = 'lbfgs', max_iter = 300, penalty = 'l2')\n",
    "\n",
    "logreg_temp.fit(X_train, y_train)\n",
    "logreg_temp.score(custom_test_X, custom_test_y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is able to predict ~11% of positive class -- almost perfect classifier of negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Testing - Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93789092, 0.94036152, 0.9388604 , 0.94079935, 0.93914186])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_clas = RandomForestClassifier(n_jobs = -1, n_estimators = 10) ## n_job = -1 to utlize all cores, n_estimator set \n",
    "                                                                  ## to default to silence update warning\n",
    "\n",
    "cross_val_score(for_clas, df_train_X, df_train_y,\n",
    "                cv = ShuffleSplit(n_splits = 5, test_size = 0.2),\n",
    "                error_score = 'raise') ## custom cv to ensure real randomization of splits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g36e3.000\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [50, 100, 200], 'max_depth' : [12, 24, 36]}\n",
    "for_clas = RandomForestClassifier(n_jobs = -1)\n",
    "clf = GridSearchCV(for_clas, parameters)\n",
    "clf_result = clf.fit(X_train, y_train)\n",
    "best_params = clf_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 24, 'n_estimators': 200}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g36e3.000\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {'min_samples_split': [2, 5, 9], 'min_samples_leaf' : [3, 7, 13]}\n",
    "for_clas = RandomForestClassifier(n_jobs = -1, n_estimators = 200, max_depth = 24)\n",
    "clf = GridSearchCV(for_clas, parameters)\n",
    "clf_result = clf.fit(X_train, y_train)\n",
    "best_params = clf_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 3, 'min_samples_split': 9}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth of 24 allows for the highest score by optimzing the proportation of correct positive class guesses and negative class guesses. n_estimators of 200 allows for high accuracy without sacrificing run-time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Model Performance - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94336377, 0.94567801, 0.94739805, 0.94520891, 0.94480235])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_clas = RandomForestClassifier(n_jobs = -1, max_depth = 24, n_estimators = 200,\n",
    "                                 min_samples_leaf = 3, min_samples_split = 9) ## n_job = -1 to utlize all cores \n",
    "\n",
    "cross_val_score(for_clas, df_train_X, df_train_y,\n",
    "                cv = ShuffleSplit(n_splits = 5, test_size = 0.2),\n",
    "                error_score = 'raise') ## custom cv to ensure real randomization of splits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned model is objectively better at classifying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Positive Class only Training Set - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932166890982503"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_test = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "custom_test = custom_test[custom_test['compliance'] == 0]\n",
    "custom_test_X = custom_test.iloc[:,:-1]\n",
    "custom_test_y = custom_test['compliance']\n",
    "\n",
    "for_clas_temp = RandomForestClassifier(n_estimators = 200,\n",
    "                                       max_depth  = 24, n_jobs = -1)\n",
    "\n",
    "for_clas_temp.fit(X_train, y_train)\n",
    "for_clas_temp.score(custom_test_X, custom_test_y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned RFC is approximately 3 times better at classifing the positive class than the LOGREG classifier and is able to identify ~35% of the positive class -- it's an almost perfect classifier of the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tuned Model for Real Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>284932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369851</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           compliance\n",
       "ticket_id            \n",
       "284932            0.0\n",
       "285362            0.0\n",
       "285361            0.0\n",
       "285338            0.0\n",
       "285346            0.0\n",
       "...               ...\n",
       "376496            0.0\n",
       "376497            0.0\n",
       "376499            0.0\n",
       "376500            0.0\n",
       "369851            1.0\n",
       "\n",
       "[60996 rows x 1 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_clas = RandomForestClassifier(n_estimators = 200, max_depth = 24, n_jobs = -1)\n",
    "for_clas.fit(df_train_X, df_train_y)\n",
    "\n",
    "df_test_X = pd.get_dummies(df_test[cols_train])\n",
    "\n",
    "predict_result = for_clas.predict(df_test_X.drop(\n",
    "    columns = ['disposition_Responsible (Fine Waived) by Admis',\n",
    "       'disposition_Responsible - Compl/Adj by Default',\n",
    "       'disposition_Responsible - Compl/Adj by Determi',\n",
    "               'disposition_Responsible by Dismissal'\n",
    "              ]))\n",
    "\n",
    "pd.DataFrame(index = df_test['ticket_id'], data = {'compliance' : predict_result})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
